{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "#   ARRAY MANIPULATION\n",
    "# -----------------------------------------------\n",
    "def is_unique(arr,rate=False):\n",
    "    \"\"\"\n",
    "    Return a boolean value for whether all elements in the array is unique, or as a rate\n",
    "    \"\"\"\n",
    "    if rate:\n",
    "        return len(np.unique(arr))/len(arr)\n",
    "    else:\n",
    "        return len(np.unique(arr)) == len(arr)\n",
    "\n",
    "def overlap(*arrs):\n",
    "    \"\"\"\n",
    "    Return the set of overlapped elements, i.e. the intersection, in the form of an array\n",
    "    \"\"\"\n",
    "    overlap_set = set(arrs[0])\n",
    "    for arr in arrs[1:]:\n",
    "        overlap_set = overlap_set.intersection(set(arr))\n",
    "    return np.array(list(overlap_set))\n",
    "\n",
    "def union(*arrs):\n",
    "    \"\"\"\n",
    "    Return the union set of all arrays, in the form of an array\n",
    "    \"\"\"\n",
    "    union_set = set()\n",
    "    for arr in arrs:\n",
    "        union_set = union_set.union(set(arr))\n",
    "    return np.array(list(union_set))\n",
    "\n",
    "def difference(*arrs,how=\"outer\"):\n",
    "    \"\"\"\n",
    "    Return the difference elements in the form of an array\n",
    "    Parameters:\n",
    "        - how = `\"outer\"`: difference between the union set with the overlap set, i.e., elements that do not appear in all sets\n",
    "        - how = `\"left\"`: differece between the left (or first) set with every other set\n",
    "        - how = `\"right\"`: differece between the right (or last) set with every other set\n",
    "\n",
    "    \"\"\"\n",
    "    difference_sets = {\n",
    "        \"outer\": set(union(*arrs)) - set(overlap(*arrs)),\n",
    "        \"left\" : set(arrs[0]) - set(overlap(*arrs)),\n",
    "        \"right\": set(arrs[-1]) - set(overlap(*arrs))\n",
    "    }\n",
    "    return np.array(list(difference_sets[how]))\n",
    "\n",
    "def label_counts(arr,labels=None):\n",
    "    \"\"\" \n",
    "    @Description: Return a dict of label_counts and labels of a list-like object\n",
    "    @Parameters:\n",
    "        - arr: list-like object (LLO)\n",
    "        - labels: labels to be included in the counting, even those not in the LLO. Order-sensitive\n",
    "    \"\"\"\n",
    "    arr_ = np.array(arr).ravel() # Omitted dtype=object\n",
    "    labels = np.unique(arr_) if isNone(labels) else np.array(labels)\n",
    "    return {'counts':np.array([Counter(arr_)[lab] for lab in labels]),'labels':labels,'num_classes':len(labels)}\n",
    "\n",
    "# -----------------------------------------------\n",
    "#   DICT MANIPULATION\n",
    "# -----------------------------------------------\n",
    "\n",
    "def dict_subset(dict_obj, keys):\n",
    "    \"\"\"\n",
    "    Return a subset of the dict object based on the keys\n",
    "    \"\"\"\n",
    "    return {key:dict_obj[key] for key in list(keys)}\n",
    "\n",
    "# -----------------------------------------------\n",
    "#   LOGIC FUNCTIONS\n",
    "# -----------------------------------------------\n",
    "def isNone(var):\n",
    "    \"\"\"\n",
    "    @Description: Check if a value is None. The typical boolean expression `var == None` may give rise to error when var is a list/array\n",
    "    \"\"\"\n",
    "    return isinstance(var,type(None))\n",
    "\n",
    "def default_value(var,default_val,default_trigger=None):\n",
    "    \"\"\"\n",
    "    @Description: Set a value if variable is default value or another default trigger\n",
    "    \"\"\"\n",
    "    if isNone(default_trigger):\n",
    "        return default_val if isNone(var) else var\n",
    "    else:\n",
    "        return default_val if (type(var) != type(default_trigger)) or (var == default_trigger) else var\n",
    "\n",
    "def converse(var,choices):\n",
    "    assert len(choices)==2, \"The converse of more than 2 choices is ambiguous\"\n",
    "    return choices[0] if var == choices[1] else choices[1]\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "#   MATH FUNCTIONS\n",
    "# -----------------------------------------------\n",
    "def clamp(val,lower=0,upper=1,default_nan=0):\n",
    "    \"\"\"\n",
    "    @Description: Clamp a numerical value between lower and upper. \n",
    "    \"\"\"\n",
    "    return max(lower,min(val,upper))\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "#   STRING FORMATTING\n",
    "# -----------------------------------------------\n",
    "\n",
    "def fmt_time(seconds):\n",
    "    \"\"\"\n",
    "    Convert time in seconds to a string representation of the format hh:mm:ss\n",
    "    \"\"\"\n",
    "    seconds = int(seconds)\n",
    "    hours = math.floor(seconds / 3600)\n",
    "    minutes = math.floor((seconds % 3600) / 60)\n",
    "    odd_secs = seconds % 60\n",
    "    if hours < 10: \n",
    "        hh = f'0{hours}' \n",
    "    else: \n",
    "        hh = f'{hours}'\n",
    "    if minutes < 10 : \n",
    "        mm = f'0{minutes}'\n",
    "    else : \n",
    "        mm = f'{minutes}'\n",
    "    if odd_secs < 10 : \n",
    "        ss = f'0{int(odd_secs)}'\n",
    "    else: \n",
    "        ss = f'{int(odd_secs)}'\n",
    "    return f'{hh}:{mm}:{ss}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .utils import *\n",
    "import time\n",
    "\n",
    "# -----------------------------------------------\n",
    "#   DICT LIKE DUMMY OBJECT\n",
    "# -----------------------------------------------\n",
    "class MyObj():\n",
    "    \"\"\"\n",
    "    @Description: Object that serves as a namespace for related attributes within other classes\n",
    "    @Example:\n",
    "        cpa = CPA1()\\n\n",
    "        cpa.var1 = MyObj()\\n\n",
    "        cpa.var1.inputs = [1,2,3]\\n\n",
    "        print(cpa.var1.inputs)\\n\n",
    "        >> [1, 2, 3]\\n\n",
    "        cpa.var2 = MyObj({'a':1,'b':2})\\n\n",
    "        print(cpa.var2.a,cpa.var2.b)\\n\n",
    "        >> 1 2\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,__name__=\"My Object\",**kwargs):\n",
    "        super(MyObj,self)\n",
    "        self.__name__ = __name__\n",
    "        self.dict_ = {}\n",
    "        self.update(**kwargs)\n",
    "\n",
    "    def update(self,**kwargs):\n",
    "        if kwargs:\n",
    "            self.dict_.update(kwargs)\n",
    "            for key,value in kwargs.items():\n",
    "                self.__setattr__(key,value)\n",
    "    \n",
    "    def dict(self,keys=None):\n",
    "        \"\"\"\n",
    "        Return the dictionary for all or a subset of attributes\n",
    "        \"\"\"\n",
    "        if isNone(keys):\n",
    "            return self.dict_\n",
    "        else:\n",
    "            return dict_subset(self.dict_,keys)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__name__} {self.dict_}'\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "#   TIMER FOR PROCESSES/TASKS\n",
    "# -----------------------------------------------\n",
    "\n",
    "class ProcessTimer:\n",
    "    def __init__(self) -> None:\n",
    "        self.start_ = {}\n",
    "        self.prev_ = {}\n",
    "        self.curr_ = {}\n",
    "        self.NEW_ID = 0;\n",
    "\n",
    "    def start(self,job_id=None):\n",
    "        job_id = self.NEW_ID if job_id is None else job_id\n",
    "        self.start_[job_id] = time.time()\n",
    "        self.curr_[job_id] = self.start_[job_id]\n",
    "        self.prev_[job_id] = -1\n",
    "        self.NEW_ID += 1\n",
    "\n",
    "    def record(self,job_id=0):\n",
    "        self.prev_[job_id] = self.curr_[job_id]\n",
    "        self.curr_[job_id] = time.time()\n",
    "\n",
    "    def execute(self,func,job_id=-1,**func_args):\n",
    "        \"\"\"\n",
    "        Record the time for executing a function.\n",
    "\n",
    "        Return \n",
    "        ---------\n",
    "        Return the time of execution followed by the function followed by the return value(s)\n",
    "        \"\"\"\n",
    "        self.start(job_id)\n",
    "        return_val = func(**func_args)\n",
    "        self.record(job_id)\n",
    "        if isNone(return_val):\n",
    "            return self.time_elapsed(job_id)\n",
    "        else:\n",
    "            return self.time_elapsed(job_id),return_val\n",
    "\n",
    "    def step_elapsed(self,job_id=0):\n",
    "        return -1 if (job_id not in self.prev_.keys() or job_id not in self.curr_.keys()) else self.curr_[job_id] - self.prev_[job_id]\n",
    "\n",
    "    def time_elapsed(self,job_id=0):\n",
    "        return -1 if (job_id not in self.start_.keys() or job_id not in self.curr_.keys()) else self.curr_[job_id] - self.start_[job_id]\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from .utils import *\n",
    "\n",
    "#----------------------------------------\n",
    "#   EXTRACT DATA FRAME INFORMATION\n",
    "#----------------------------------------\n",
    "\n",
    "def summary(df:pd.DataFrame|pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summary table for each columns in the dataframe\n",
    "    \"\"\"\n",
    "    df_sum = pd.DataFrame(index=df.columns,columns=[\"dtypes\",\"length\",\"unique\",\"samples\",\"mode\",\"range\",\"mean\",\"std\",\"fill\"])\n",
    "    df_sum.index.name = \"columns\"\n",
    "    for c in df.columns:\n",
    "        df_c_notna = df[c][df[c].notna()]\n",
    "        df_sum.loc[c,\"dtypes\"] = df[c].dtypes\n",
    "        df_sum.loc[c,\"samples\"] = (list(df[c].value_counts(ascending=False).index.values[:5]))\n",
    "        df_sum.loc[c,\"length\"] = len(df[c])\n",
    "        df_sum.loc[c,\"unique\"] = len(df[c].unique())\n",
    "        df_sum.loc[c,\"mode\"] = df_c_notna.mode()[0]\n",
    "        df_sum.loc[c,\"fill\"] = np.round(len(df_c_notna)/len(df[c]),2)\n",
    "        if isinstance(df[c].dtype,(type(np.dtype(\"float64\")),type(np.dtype(\"int64\")))):\n",
    "            df_sum.loc[c,\"range\"] = ([df_c_notna.min(),df_c_notna.max()])\n",
    "            df_sum.loc[c,\"mean\"] = df_c_notna.mean().round(2)\n",
    "            df_sum.loc[c,\"std\"] = df_c_notna.std().round(2)\n",
    "    return df_sum\n",
    "\n",
    "def compare(df1 : pd.DataFrame|pd.Series, df2: pd.DataFrame|pd.Series,numeric: bool=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare the 2 DataFrames along the same indexes and columns. \n",
    "        - For numeric columns, return the difference. \n",
    "        - For object columns, return whether the values match\n",
    "    \"\"\"\n",
    "    overlapped_index = overlap(df1.index,df2.index)\n",
    "    overlapped_columns = overlap(df1.columns,df2.columns)\n",
    "    index = df1.index if set(df1.index) == set(overlapped_index) else overlapped_index\n",
    "    columns = df1.columns if set(df1.columns) == set(overlapped_columns) else overlapped_columns\n",
    "    df1_comp = df1.loc[index,columns]\n",
    "    df2_comp = df2.loc[index,columns]\n",
    "    df_comp = pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "    if numeric:\n",
    "        numeric_cols = []\n",
    "        for c in columns:\n",
    "            if is_np_numeric(df1[c]) and is_np_numeric(df2[c]): \n",
    "                numeric_cols.append(c)\n",
    "                df_comp.loc[index,c] = (df1_comp.loc[index,c] - df2_comp.loc[index,c])\n",
    "        return df_comp.loc[index,numeric_cols]\n",
    "\n",
    "    else:\n",
    "        for c in columns:\n",
    "            df_comp.loc[index,c] = (df1_comp.loc[index,c] == df2_comp.loc[index,c]) | ((df1_comp.loc[index,c] != df2_comp.loc[index,c]) \n",
    "                                                                                        & (df1_comp.loc[index,c].isna() == df2_comp.loc[index,c].isna())\n",
    "                                                                                        & df1_comp.loc[index,c].isna() \n",
    "                                                                                        & df2_comp.loc[index,c].isna())\n",
    "        return df_comp.loc[index,columns]\n",
    "\n",
    "#----------------------------------------\n",
    "# DATA FRAME MANIPULATION & TRANSFORMATION\n",
    "#----------------------------------------\n",
    "\n",
    "def filter(df: pd.DataFrame|pd.Series, condition: pd.DataFrame|pd.Series, filter_columns: bool=False) -> pd.DataFrame|pd.Seires:\n",
    "    \"\"\"\n",
    "    @Description: Filter a `DataFrame` object based on a match over one or multiple columns. Results can be filtered by rows or both rows and columns.\n",
    "    @Parameters:\n",
    "        - condition: boolean Series, typically a DataFrame expression involving one or more conditions. E.g., `df['A'] == 1` or `df[['B','C']] == [2,3]`\n",
    "        - filter_columns: When filter_columns is False, only filter by rows, otherwise filter by both rows and columns\n",
    "    \"\"\"\n",
    "    df_ = pd.DataFrame(df)\n",
    "    filter_ = pd.DataFrame(condition)\n",
    "    # Ensure that condition works over multiple columns matching\n",
    "    match_all_columns = (pd.DataFrame(condition).sum(axis=1) == len(filter_.columns.values))\n",
    "    condition =  match_all_columns if len(filter_.columns.values) >= 1 else condition \n",
    "\n",
    "    # Select columns to keep and rows to display based on condition\n",
    "    columns_filt = filter_.columns.values if filter_columns else df_.columns.values\n",
    "    index_filt = df_.loc[:,columns_filt][condition].dropna().index    \n",
    "    return df_.loc[index_filt,columns_filt]\n",
    "\n",
    "def per_class_sample(inputs: pd.DataFrame|pd.Series, targets: pd.DataFrame|pd.Series, \n",
    "                        sampling_dist: str|int|float|Iterable='min',random_state: int=None) -> tuple[pd.DataFrame|pd.Series, pd.DataFrame|pd.Series]:\n",
    "    \"\"\"\n",
    "    ### Description: \n",
    "    Sample inputs based on a distribution of target labels. By default will attempt to sample all classes equally according to the least populous class.\n",
    "\n",
    "    ### Parameters:\n",
    "    - sampling_dist:\n",
    "        - If sampling_dist is `None`: Sample all classes .\n",
    "        - If sampling_dist is `min`: Attempt to sample all classes equally according to the least populous class.\n",
    "        - If sampling_dist is type `int`: Attempt to sample all classes up to a maximum of label_dists\n",
    "        - If sampling_dist is type `float` (within (0,1)): Attempt to sample all classes each with the proportion of label_dists\n",
    "        - If sampling_dist is type `list`: Attempt to sample classes based on the distribution specified.\n",
    "            - If a class distribution is `None`, all members of that class is sampled\n",
    "            - If a class distribution is a fraction (within (0,1)), it will be understood as the class proportion\n",
    "            - If a class distribution is an integer (>=1), it will be understood as class counts\n",
    "    \"\"\"\n",
    "    # Convert sampling_dist into list of distribution if not already is\n",
    "    counts,labels,num_labels = label_counts(targets).values()\n",
    "    if isNone(sampling_dist):\n",
    "        sampling_dist = counts\n",
    "    if isinstance(sampling_dist,str) & sampling_dist == 'min':\n",
    "        sampling_dist = min(counts)\n",
    "    if isinstance(sampling_dist,(int,float)):\n",
    "        sampling_dist = np.full(shape = labels.shape,fill_value = sampling_dist)\n",
    "\n",
    "    sampled_index = pd.Index([])\n",
    "    for labels_i,counts_i, sampling_dist_i in zip(labels,counts,sampling_dist):\n",
    "        # Convert distribution values to actual class counts\n",
    "        if isNone(sampling_dist_i): \n",
    "            dist_i = int(counts_i)\n",
    "        elif 0 <= sampling_dist_i and sampling_dist_i < 1:\n",
    "            dist_i = int(counts_i * sampling_dist_i)\n",
    "        else:\n",
    "            dist_i = int(clamp(sampling_dist_i,0,counts_i))\n",
    "        # Obtain samples with the labels_i   \n",
    "        sampled_targets_i = filter(targets,targets==labels_i).sample(dist_i,random_state=random_state)\n",
    "        sampled_index = sampled_index.append(sampled_targets_i.index)\n",
    "\n",
    "    return inputs.loc[sampled_index], targets.loc[sampled_index]\n",
    "\n",
    "\n",
    "def match(df_in: pd.DataFrame|pd.Series, oper: str ,values: Iterable[int],strict: bool=False) -> pd.DataFrame|pd.Series:\n",
    "    \"\"\"\n",
    "    Apply a comparison operation to a list of values and return all results that matches all elements in the list.\n",
    "\n",
    "    In strict mode, only keep rows that satisfy all matching requirements \n",
    "    \"\"\"\n",
    "    mult_result = (df_in != df_in) if oper == \"==\" else (df_in == df_in)\n",
    "    for val in np.array(values):\n",
    "        mult_result = {\n",
    "            \"<=\": mult_result & (df_in <= val), \"<\"  : mult_result & (df_in < val),\n",
    "            \">=\": mult_result & (df_in >= val), \">\"  : mult_result & (df_in > val),\n",
    "            \"==\": mult_result | (df_in == val), \"!=\" : mult_result & (df_in != val),\n",
    "        } [oper]\n",
    "    df_out = df_in[mult_result].dropna(how={True:\"any\",False:\"all\"}[strict])\n",
    "    return df_out\n",
    "\n",
    "#----------------------------------------\n",
    "#   DATA TYPES\n",
    "#----------------------------------------\n",
    "\n",
    "def is_np_dtypes(series: pd.Series ,dtypes : str|tuple|Iterable) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a series is of one or multiple numpy dtypes\n",
    "    - For `int` dtype, use `\"int64\"`\n",
    "    - For `float` dtype, use  `\"float64\"`\n",
    "    - For `object` dtype, use  `\"O\"`\n",
    "    \"\"\"\n",
    "    return isinstance(series.dtypes,tuple([type(np.dtype(typ)) for typ in dtypes]))\n",
    "\n",
    "def is_np_numeric(series: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a series is of numeric numpy dtypes\n",
    "    \"\"\"\n",
    "    return is_np_dtypes(series,(\"float64\",\"int64\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>c10</th>\n",
       "      <th>c11</th>\n",
       "      <th>c12</th>\n",
       "      <th>c13</th>\n",
       "      <th>c14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>43</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>20</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>45</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>47</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43.0</td>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>24</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     c0  c1    c2  c3    c4    c5    c6    c7    c8    c9   c10   c11  c12  \\\n",
       "0  37.0  43  12.0   8   9.0  11.0   NaN  15.0   NaN  16.0   NaN  12.0    7   \n",
       "1  25.0  20  37.0  18  20.0  11.0  42.0  28.0  29.0  14.0   NaN  23.0   23   \n",
       "2  30.0  32  22.0  13  41.0   9.0   7.0  22.0   NaN   NaN  17.0   8.0   24   \n",
       "3  42.0   8  30.0   7   NaN   6.0  21.0  49.0   NaN   NaN  24.0  49.0   43   \n",
       "4  16.0  45  41.0  18  15.0   NaN   NaN  25.0  47.0  34.0  23.0   7.0   26   \n",
       "5  22.0   9   NaN  39  23.0  36.0  27.0  37.0  19.0  38.0   8.0  32.0   34   \n",
       "6  15.0  47  23.0  25   7.0  28.0  10.0  46.0  32.0  24.0  23.0   NaN   49   \n",
       "7   NaN  13   6.0  21   6.0   NaN  12.0  27.0  21.0  11.0   7.0  13.0    8   \n",
       "8  43.0  20  30.0  36  39.0   7.0  45.0   NaN  48.0  18.0  32.0  13.0   10   \n",
       "9   7.0  24  10.0  28  20.0  32.0  12.0   NaN  30.0  41.0  24.0  18.0   33   \n",
       "\n",
       "    c13   c14  \n",
       "0  45.0   6.0  \n",
       "1  41.0  49.0  \n",
       "2  13.0  47.0  \n",
       "3  12.0  26.0  \n",
       "4  25.0  40.0  \n",
       "5  10.0  23.0  \n",
       "6  13.0   NaN  \n",
       "7  11.0  12.0  \n",
       "8  23.0  17.0  \n",
       "9   NaN  44.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/random_dataframe/random_dataframe_1.csv\").drop(columns=\"Unnamed: 0\")\n",
    "df_in = df[df>5]\n",
    "df_in"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
